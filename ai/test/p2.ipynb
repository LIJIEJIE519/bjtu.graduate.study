{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iris.pdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "iris = load_iris()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "digraph Tree {\n",
      "node [shape=box] ;\n",
      "0 [label=\"X[2] <= 2.45\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]\"] ;\n",
      "1 [label=\"gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"X[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]\"] ;\n",
      "0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "3 [label=\"X[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"X[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]\"] ;\n",
      "3 -> 4 ;\n",
      "5 [label=\"gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]\"] ;\n",
      "4 -> 5 ;\n",
      "6 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]\"] ;\n",
      "4 -> 6 ;\n",
      "7 [label=\"X[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]\"] ;\n",
      "3 -> 7 ;\n",
      "8 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]\"] ;\n",
      "7 -> 8 ;\n",
      "9 [label=\"X[0] <= 6.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]\"] ;\n",
      "7 -> 9 ;\n",
      "10 [label=\"gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]\"] ;\n",
      "9 -> 10 ;\n",
      "11 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]\"] ;\n",
      "9 -> 11 ;\n",
      "12 [label=\"X[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]\"] ;\n",
      "2 -> 12 ;\n",
      "13 [label=\"X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]\"] ;\n",
      "12 -> 13 ;\n",
      "14 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]\"] ;\n",
      "13 -> 14 ;\n",
      "15 [label=\"gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]\"] ;\n",
      "13 -> 15 ;\n",
      "16 [label=\"gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]\"] ;\n",
      "12 -> 16 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)\n",
    "print(iris.target)\n",
    "print(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对y的各种可能的取值出现的个数进行计数.。其他函数利用该函数来计算数据集和的混杂程度\n",
    "def uniquecounts(rows):\n",
    "    results = {}\n",
    "    for row in rows:\n",
    "        #计数结果在最后一列\n",
    "        r = row[len(row)-1]\n",
    "        if r not in results:results[r] = 0\n",
    "        results[r]+=1\n",
    "    return results # 返回一个字典\n",
    "\n",
    "\n",
    "# 熵\n",
    "\n",
    "\n",
    "def entropy(rows):\n",
    "    from math import log\n",
    "    log2 = lambda x:log(x)/log(2)\n",
    "    results = uniquecounts(rows)\n",
    "    #开始计算熵的值\n",
    "    ent = 0.0\n",
    "    for r in results.keys():\n",
    "        p = float(results[r])/len(rows)\n",
    "        ent = ent - p*log2(p)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义节点的属性\n",
    "class decisionnode:\n",
    "    def __init__(self,col = -1,value = None, results = None, tb = None,fb = None):\n",
    "        self.col = col   # col是待检验的判断条件所对应的列索引值\n",
    "        self.value = value # value对应于为了使结果为True，当前列必须匹配的值\n",
    "        self.results = results #保存的是针对当前分支的结果，它是一个字典\n",
    "        self.tb = tb ## desision node,对应于结果为true时，树上相对于当前节点的子树上的节点\n",
    "        self.fb = fb ## desision node,对应于结果为true时，树上相对于当前节点的子树上的节点\n",
    "\n",
    "\n",
    "# 基尼不纯度\n",
    "\n",
    "\n",
    "# 随机放置的数据项出现于错误分类中的概率\n",
    "def giniimpurity(rows):\n",
    "    total = len(rows)\n",
    "    counts = uniquecounts(rows)\n",
    "    imp =0\n",
    "    for k1 in counts:\n",
    "        p1 = float(counts[k1])/total\n",
    "        for k2 in counts: # 这个循环是否可以用（1-p1）替换？\n",
    "            if k1 == k2: continue\n",
    "            p2 = float(counts[k2])/total\n",
    "            imp+=p1*p2\n",
    "    return imp\n",
    "\n",
    "\n",
    "# 改进giniimpurity\n",
    "\n",
    "\n",
    "def giniimpurity_2(rows):\n",
    "    total = len(rows)\n",
    "    counts = uniquecounts(rows)\n",
    "    imp = 0\n",
    "    for k1 in counts.keys():\n",
    "        p1 = float(counts[k1])/total\n",
    "        imp+= p1*(1-p1)\n",
    "    return imp\n",
    "\n",
    "\n",
    "\n",
    "#在某一列上对数据集进行拆分。可应用于数值型或因子型变量\n",
    "def divideset(rows,column,value):\n",
    "    #定义一个函数，判断当前数据行属于第一组还是第二组\n",
    "    split_function = None\n",
    "    if isinstance(value,int) or isinstance(value,float):\n",
    "        split_function = lambda row:row[column] >= value\n",
    "    else:\n",
    "        split_function = lambda row:row[column]==value\n",
    "    # 将数据集拆分成两个集合，并返回\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "    return(set1,set2)\n",
    "\n",
    "\n",
    "# 以递归方式构造树\n",
    "\n",
    "def buildtree(rows,scoref = entropy):\n",
    "    if len(rows)==0 : return decisionnode()\n",
    "    current_score = scoref(rows)\n",
    "    \n",
    "    # 定义一些变量以记录最佳拆分条件\n",
    "    best_gain = 0.0\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "    \n",
    "    column_count = len(rows[0]) - 1\n",
    "    for col in range(0,column_count):\n",
    "        #在当前列中生成一个由不同值构成的序列\n",
    "        column_values = {}\n",
    "        for row in rows:\n",
    "            column_values[row[col]] = 1 # 初始化\n",
    "        #根据这一列中的每个值，尝试对数据集进行拆分\n",
    "        for value in column_values.keys():\n",
    "            (set1,set2) = divideset(rows,col,value)\n",
    "            \n",
    "            # 信息增益\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = current_score - p*scoref(set1) - (1-p)*scoref(set2)\n",
    "            if gain>best_gain and len(set1)>0 and len(set2)>0:\n",
    "                best_gain = gain\n",
    "                best_criteria = (col,value)\n",
    "                best_sets = (set1,set2)\n",
    "                \n",
    "    #创建子分支\n",
    "    if best_gain>0:\n",
    "        trueBranch = buildtree(best_sets[0])  #递归调用\n",
    "        falseBranch = buildtree(best_sets[1])\n",
    "        return decisionnode(col = best_criteria[0],value = best_criteria[1],\n",
    "                            tb = trueBranch,fb = falseBranch)\n",
    "    else:\n",
    "        return decisionnode(results = uniquecounts(rows))\n",
    "\n",
    "# 决策树的显示\n",
    "def printtree(tree,indent = ''):\n",
    "    # 是否是叶节点\n",
    "    if tree.results!=None:\n",
    "        print(str(tree.results))\n",
    "    else:\n",
    "        # 打印判断条件\n",
    "        print(str(tree.col)+\":\"+str(tree.value)+\"? \")\n",
    "        #打印分支\n",
    "        print(indent+\"T->\")\n",
    "        printtree(tree.tb,indent+\" \")\n",
    "        print(indent+\"F->\")\n",
    "        printtree(tree.fb,indent+\" \")\n",
    "\n",
    "\n",
    "# 对新的观测数据进行分类\n",
    "\n",
    "\n",
    "def classify(observation,tree):\n",
    "    if tree.results!= None:\n",
    "        return tree.results\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        branch = None\n",
    "        if isinstance(v,int) or isinstance(v,float):\n",
    "            if v>= tree.value: branch = tree.tb\n",
    "            else: branch = tree.fb\n",
    "        else:\n",
    "            if v==tree.value : branch = tree.tb\n",
    "            else: branch = tree.fb\n",
    "        return classify(observation,branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=[['slashdot','USA','yes',18,'None'],\n",
    "        ['google','France','yes',23,'Premium'],\n",
    "        ['digg','USA','yes',24,'Basic'],\n",
    "        ['kiwitobes','France','yes',23,'Basic'],\n",
    "        ['google','UK','no',21,'Premium'],\n",
    "        ['(direct)','New Zealand','no',12,'None'],\n",
    "        ['(direct)','UK','no',21,'Basic'],\n",
    "        ['google','USA','no',24,'Premium'],\n",
    "        ['slashdot','France','yes',19,'None'],\n",
    "        ['digg','USA','no',18,'None'],\n",
    "        ['google','UK','no',18,'None'],\n",
    "        ['kiwitobes','UK','no',19,'None'],\n",
    "        ['digg','New Zealand','yes',12,'Basic'],\n",
    "        ['slashdot','UK','no',21,'None'],\n",
    "        ['google','UK','yes',18,'Basic'],\n",
    "        ['kiwitobes','France','yes',19,'Basic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:google? \n",
      "T->\n",
      "3:21? \n",
      " T->\n",
      "{'Premium': 3}\n",
      " F->\n",
      "2:no? \n",
      "  T->\n",
      "{'None': 1}\n",
      "  F->\n",
      "{'Basic': 1}\n",
      "F->\n",
      "0:slashdot? \n",
      " T->\n",
      "{'None': 3}\n",
      " F->\n",
      "2:yes? \n",
      "  T->\n",
      "{'Basic': 4}\n",
      "  F->\n",
      "3:21? \n",
      "   T->\n",
      "{'Basic': 1}\n",
      "   F->\n",
      "{'None': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Basic': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "divideset(my_data,2,'yes')\n",
    "\n",
    "\n",
    "giniimpurity(my_data)\n",
    "\n",
    "\n",
    "giniimpurity_2(my_data)\n",
    "\n",
    "\n",
    "tree = buildtree(my_data)\n",
    "\n",
    "\n",
    "printtree(tree = tree)\n",
    "\n",
    "\n",
    "classify(['(direct)','USA','yes',5],tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
